# 机器学习笔记

## 第一章 绪论

### 1.1.机器学习

​	致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。

- 经验：通常以数据的形式存在。
- 机器学习所研究的主要内容是关于在计算机上从数据中产生模型的算法，即学习算法。

### 1.2.基本术语

1. 数据集：收集的数据的集合。其中每一条记录是关于一个事件或者对象的描述，称为一个示例或者样本。
2. 属性：反应时间或者对象在某方面的表现或性质的事项，也可以叫做特征。
3. 属性空间：属性张成的空间，也可以叫做样本空间或者输入空间。
4. 样本维数：每个示例的属性数称为样本的维数。
5. 训练集：训练过程中使用的数据。
6. 模型：模型对应了关于数据的某种潜在的规律，因此也可以称为假设。规律本身叫做真相或者真实，学习过程是为了找出或逼近真相。
7. 标记：关于示例结果的信息。拥有标记信息的示例称为样例。
8. 标记空间（输出空间）：所有标记的集合。
9. 分类：预测的是离散值。
10. 回归：预测的是连续值。
11. 测试：学的模型后，使用其进行预测的过程称为测试。
12. 测试样本：被测试的样本。
13. 聚类：将训练集中的样本分成若干组，每组称为一个族。
14. 监督学习：拥有标记信息，分类和回归是其代表。
15. 无监督学习：没有标记信息，聚类是其代表。
16. 泛化能力：学得的模型适用于新样本的能力。

### 1.3假设空间

1. 归纳：从特殊到一般的泛化过程。
2. 演绎：从一般到特殊的特化过程。
3. 归纳学习：从样例中学习显然是一个归纳过程，因此成为归纳学习。
4. 广义归纳学习：相当于从样例中学习。
5. 狭义归纳学习：要求从训练数据中学得概念，因此也成为概念学习或者概念形成。
6. 假设空间：学习过程可以看做一个在所有假设组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设。假设的表示一旦确定，假设空间及其规模大小就确定了。
7. 版本空间：现实问题中我们常面临很大的假设空间，但学习过程是基于有限样本训练集进行的，因此可能多个假设与训练集一致，即存在一个与训练集一致的假设集合，我们称之为版本空间。

### 1.4归纳偏好

1. 归纳偏好：机器学习算法在学习过程中对某种类型假设的偏好，称为归纳偏好。简称为偏好。任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上等效的假设所迷惑，而无法产生确定的学习结果。
2. 奥卡姆剃刀：一种常用的、自然科学研究中最基本的原则，即：若有多个假设与观察一直，则选择最简单的那个。

## 第二章 模型评估与选择

### 2.1 经验误差与过拟合

1. 错误率(error)：错误分类的样本数占样本总数的比例称为错误率。E = a / m.
2. 精度(accuracy):精度 = 1 - 错误率，即1 - a / m.
3. 误差：模型的实际预测输出与样本的真实输出之间的差异称为误差。
4. 训练误差(经验误差)：模型在训练集上的误差。
5. 泛化误差：模型在新样本上的误差。
6. 过拟合：当模型把训练样本学的太好了的时候，很可能已经把训练样本本身的一些特点当做了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降。这种现象在机器学习中称为过拟合。
7. 欠拟合：对训练样本的一般性质尚未学好称为欠拟合。和过拟合相对。
8. 欠拟合解决方法：在决策树学习中扩展分支、在神经网络学习中增加训练轮数等。
9. 过拟合无法彻底避免，只能缓解，或者说减小其风险。
10. 模型选择：在现实任务中，往往有多种学习算法可供选择，甚至对同一个学习算法，当使用不同的参数配置时，也会产生不同的模型。理想的解决方案是对候选模型的泛化误差进行评估，然后选择泛化误差最小的那个模型。我们无法直接获得泛化误差，而训练误差又由于过拟合现象的存在而不适合作为标准，因此需要用到下面介绍的评估方法。
11. 评估方法：通常通过实验测试来对模型的泛化误差进行评估并进而做出选择。为此，需要用一个测试集来测试模型对新样本的判别能力，然后以测试集上的测试误差作为泛化误差的近似。测试集应尽可能与训练集互斥，即测试样本尽量不在训练集中出现、为在训练过程中使用过。
12. 数据集划分的方法：
    - 留出法：直接将数据集划分为两个互斥的集合，其中一个集合作为训练集，另一个作为测试集。需注意的是，划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响。 另外需要注意的问题是，即使在给定训练/测试集的样本比例后，人存在多种划分初始数据集的方式。单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法是，一般要采用若干次随机划分、重复进行试验评估后取平均值作为留出法的评估结果。留出法常见做法是将大约3/2~4/5的样本用于训练，剩余样本用于测试。
    - 交叉验证法：先将数据集划分为k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性，即从数据集中通过分层采用得到。然后每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值。k最常用的取值是10，此时称为10折交叉验证。
    - 自助法：直接以自助采样法为基础，给定包含m个样本的数据集D，对它进行采样产生数据集D'。每次随机从D中挑选一个样本，将其拷贝放入D'，然后再将样本放回初始数据集D中，使得该样本在下次采样时人有可能被采到，这个过程重复执行m次后，就得到了包含m个样本的数据集D',这就是自助采样的结果。通过自助采样，初始数据集D中大约有36.8%的样本未出现在采样数据集D‘中。自助法在数据集较小，难以有效划分训练/测试集时很有用；此外，自助法能从初始数据及中产生多个不同的训练集，这对集成学习等方法有很大好处。在初始数据量足够时，留出法和交叉验证法更常用一些。
13. 调参与最终模型：
    - 调参：大多数学习算法都有些参数需要设定，参数配置不同，学得的模型的性能往往有显著差别。因此，在进行模型评估与选择时，除了要对适用学习算法进行选择，还需要对算法参数进行设定，这就是通常所说的参数调节或者简称调参。
    - 最终模型：给定包含m个样本的数据集D，在模型评估与选择过程中由于需要留出一部分数据进行评估测试，事实上我们只使用了一部分数据训练模型。因此，在模型选择完成后，学习算法和参数配置已选定，此时应该用数据集D重新训练模型。这个模型在训练过程中使用了所有样本，这才是我们最终提交给用户的模型。
14. 性能度量：对模型的泛化性能进行评估，不仅需要有效可行的试验估计方法，还需要有衡量模型泛化能力的评价标准，这就是性能度量。它反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果，这意味着模型的好坏是相对的。
    - 回归任务最常用的性能度量是均方误差。
    - 错误率和精度
    - 查准率、查全率与F1
    - ROC与AUC：ROC全称为受试者工作特征曲线。
    - 代价敏感错误率与代价曲线
15. 比较检验
    - 假设检验
    - 交叉验证t检验
    - McNemar检验
    - Friedman检验与Nemenyi后续检验
16. 偏差与方差
    - 偏差与方差分解：是解释学习算法泛化性能的一种重要工具。偏差-方差分解试图对学习算法的期望泛化错误率进行拆解。

## 第三章 线性模型

### 3.1 基本形式

$$
f(x) = w^Tx+b,其中w=(w_1;w_2;...;w_d).
在学得w和b后，模型就得以确定。
$$

​	线性模型形式简单、易于建模，但却蕴含着机器学习中一些重要的基本思想。许多功能更为强大的非线性模型可在线性模型的基础上通过引入层级结构或高维映射而得。由于w直观表达了各属性在预测中的重要性，因此线性模型有很好的可解释性。

### 3.2 线性回归

1. 线性回归：试图学得一个线性模型以尽可能准确地预测实值输出标记。
2. 均方差：是回归任务中最常用的性能度量。它对应了常用的欧几里得距离，简称欧式距离。基于均方误差最小化来进行模型求解的方法称为最小二乘法。

### 3.3对数几率回归

1. 来由：考虑二分类任务，其输出标记y为0或1，而线性回归模型产生的预测值
   $$
   z=w^Tx+b
   $$
   是实值，于是我们需要将实值z转换为0/1值。最理想的是“单位阶跃函数”
   $$
   y=\begin{cases} 0,z<0; \\0.5,z=0; \\1,z<0 \end{cases}
   $$
   单位阶跃函数不连续，我们希望找到能在一定程度上近似单位阶跃函数的替代函数，并希望它单调可微，对数几率函数正是这样一个常用的替代函数：
   $$
   y=\frac{1}{1+e^-z}
   $$
   

2.对数几率函数：
$$
y=\frac{1}{1+e^-z}
$$
它是一种Sigmoid函数，它将z值转化为一个接近0或1的y值，并且其输出值在z=0附近变化很陡。

3.逻辑回归：用线性回归模型的预测结果去逼近真实标记的对数几率。它是直接对分类可能性进行建模，无需事先假设数据分布，这样就避免了假设分布不准确所带来的问题。它不是仅预测出类别，而是可得到近似概率预测，这对许多需利用概率辅助决策的任务很有用，此外，对率函数是任意阶可导的凸函数，有很好的数学性质，现有的许多数值优化算法都可以直接用于求解最优解。

4.确定w和b最优解的方法：

- 梯度下降算法
- 牛顿法

### 3.4 线性判别分析（LDA）

1. 线性判别分析：是一种经典的线性学习方法，也成为Fisher判别分析。
2. 线性判别分析的思想：给定训练样例集，设法将样例投影到一条直线上，是的同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在堆新样例进行分类是，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。

## 第四章   决策树（decision tree）

### 4.1算法的评估

- 准确率
- 速度
- 强壮性
- 可规模性
- 可解释性

### 4.2 什么是决策树

​	决策树是一个类似于流程图的树的结构，其中每一个内部结点表示在一个属性上的测试，每个分支代表一个属性输出，而每个树叶节点代表类或类分布。树的最顶层是根节点。



